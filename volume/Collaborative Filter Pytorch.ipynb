{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='data/ml-latest-small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path+'ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_uniq = ratings.userId.unique()\n",
    "user2idx = {o:i for i,o in enumerate(u_uniq)}\n",
    "ratings.userId = ratings.userId.apply(lambda x: user2idx[x])\n",
    "\n",
    "m_uniq = ratings.movieId.unique()\n",
    "movie2idx = {o:i for i,o in enumerate(m_uniq)}\n",
    "ratings.movieId = ratings.movieId.apply(lambda x: movie2idx[x])\n",
    "\n",
    "n_users=int(ratings.userId.nunique())\n",
    "n_movies=int(ratings.movieId.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDotProd(nn.Module):\n",
    "    # nn.Module inherits from pytorch module to get all the awesom pytorch\n",
    "    def __init__(self, n_users, n_movies):\n",
    "        super().__init__()\n",
    "        # creating the embedding matrices layer -> Embedding(rows, cols)\n",
    "        # creates 2 randomly initialised arrays \n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        # change the random initialised nums so that it is not to far away\n",
    "        # i.e if its too high then gradient descent starts from further away -> longer\n",
    "        # should set weight equal a normal dist w std deviation proportional to number of things in previous layer\n",
    "        self.u.weight.data.uniform_(0, 0.05)\n",
    "        self.m.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, cats, conts):\n",
    "        # grab idxs for vars\n",
    "        users, movies = cats[:,0], cats[:,1]\n",
    "        # do array lookup on embedding matrics\n",
    "        # does this a mini batch at a time does not require a loop\n",
    "        # dont loop manualy\n",
    "        u,m = self.u(users),self.m(movies)\n",
    "        #return dot product\n",
    "        return (u*m).sum(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??EmbeddingDotProd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ratings.drop(['rating', 'timestamp'], axis=1)\n",
    "\n",
    "y = ratings['rating']\n",
    "\n",
    "n_factors = 50\n",
    "val_idxs = get_cv_idxs(len(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast ai data loader, basically a python generator\n",
    "data = ColumnarModelData.from_data_frame(path, val_idxs, x, y, ['userId', 'movieId'], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay=1e-5  \n",
    "model = EmbeddingDotProd(n_users, n_movies).cuda()\n",
    "\n",
    "opt = optim.SGD(model.parameters(), 1e-1, weight_decay=weight_decay, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW `fit.()` looping training function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(model, data, epochs, opt, crit, metrics=None, callbacks=None, stepper=Stepper, **kwargs):\n",
    "    \"\"\" Fits a model\n",
    "\n",
    "    Arguments:\n",
    "       model (model): any pytorch module\n",
    "           net = to_gpu(net)\n",
    "       data (ModelData): see ModelData class and subclasses\n",
    "       opt: optimizer. Example: opt=optim.Adam(net.parameters())\n",
    "       epochs(int): number of epochs\n",
    "       crit: loss function to optimize. Example: F.cross_entropy\n",
    "    \"\"\"\n",
    "    stepper = stepper(model, opt, crit, **kwargs)\n",
    "    metrics = metrics or []\n",
    "    callbacks = callbacks or []\n",
    "    avg_mom=0.98\n",
    "    batch_num,avg_loss=0,0.\n",
    "    for cb in callbacks: cb.on_train_begin()\n",
    "    names = [\"epoch\", \"trn_loss\", \"val_loss\"] + [f.__name__ for f in metrics]\n",
    "    layout = \"{!s:10} \" * len(names)\n",
    "    \n",
    "    num_batch = len(data.trn_dl)\n",
    "    if epochs<1:\n",
    "        num_batch = int(num_batch*epochs)\n",
    "        epochs = 1\n",
    "\n",
    "    for epoch in tnrange(epochs, desc='Epoch'):\n",
    "        stepper.reset(True)\n",
    "        t = tqdm(iter(data.trn_dl), leave=False, total=num_batch)\n",
    "        i = 0\n",
    "        for (*x,y) in t:\n",
    "            batch_num += 1\n",
    "            for cb in callbacks: cb.on_batch_begin()\n",
    "            loss = stepper.step(V(x),V(y))\n",
    "            avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)\n",
    "            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n",
    "            t.set_postfix(loss=debias_loss)\n",
    "            stop=False\n",
    "            for cb in callbacks: stop = stop or cb.on_batch_end(debias_loss)\n",
    "            if stop: return\n",
    "            if i>num_batch: break\n",
    "            i += 1\n",
    "\n",
    "        vals = validate(stepper, data.val_dl, metrics)\n",
    "        if epoch == 0: print(layout.format(*names))\n",
    "        print_stats(epoch, [debias_loss] + vals)\n",
    "        stop=False\n",
    "        for cb in callbacks: stop = stop or cb.on_epoch_end(vals)\n",
    "        if stop: break\n",
    "\n",
    "    for cb in callbacks: cb.on_train_end()\n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-09a5bc469dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "fit(model, data, 3, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d21c0f87433c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset_lrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "set_lrs(opt, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a7bbe9f2d64296afa23caf0f28c73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.73007    1.147822  \n",
      "    1      0.726418   1.135568                                  \n",
      "    2      0.691686   1.128838                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1288381]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, data, 3, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  1  1\n",
       "  2  2\n",
       " [torch.FloatTensor of size 2x2], \n",
       "  2  3\n",
       "  5  6\n",
       " [torch.FloatTensor of size 2x2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,1],[2,2]])\n",
    "t2 = torch.FloatTensor([[2,3],[5,6]])\n",
    "t,t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3  4\n",
       " 7  8\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t+t2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
