{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FitLam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip\n",
    "\n",
    "download dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR maybe use Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: wget: not found\r\n"
     ]
    }
   ],
   "source": [
    "# !wget -nH -r -np http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "\n",
    "from fastai.text import *\n",
    "from torchtext import vocab, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/fitlam')\n",
    "PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(Path('/notebooks/volume/full_hemingway.txt'), encoding='utf-8')\n",
    "fulltext = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the joined collection of hemingway books 80/20. This may not be very valid, maybe the whole book should be a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to files\n",
    "def save_txt_file(name, txt):    \n",
    "    f=open(PATH/name, mode='w', encoding='utf-8')\n",
    "    f.write(txt)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_txt_file('hemingway.trn.txt', trn)\n",
    "save_txt_file('hemingway.val.txt', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize='spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_txt = set(fulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cln_full_txt = fulltext.replace('\\u2009', ' ').replace('“', '').replace('”', '').replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ing-boat. The mountains were sharp and steep on the other side of the lake and down at the end of the lake was the plain of the Rhone Valley flat between the two ranges of mountains; and up the valley where the mountains cut it off was the Dent du Midi. It was a high snowy mountain and it dominated '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.random.randint(1,len(cln_full_txt))\n",
    "cln_full_txt[r:(r+300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng = len(cln_full_txt)\n",
    "trn_str,val_str = [cln_full_txt[0:int(lng*i)] for i in [0.8,0.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = Tokenizer().proc_text(trn_str)\n",
    "tok_val = Tokenizer().proc_text(val_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91388 [' ' 'robert' 'cohn' 'was' 'once' 'middleweight' 'boxing' 'champion' 'of' 'princeton' '.' 'do' 'not' 'think'\n",
      " 'that' 'i' 'am' 'very' 'much' 'impressed' 'by' 'that' 'as' 'a' 'boxing' 'title' ',' 'but' 'it' 'meant' 'a'\n",
      " 'lot' 'to' 'cohn' '.' 'he' 'cared' 'nothing' 'for' 'boxing']\n",
      "363798 [' ' 'robert' 'cohn' 'was' 'once' 'middleweight' 'boxing' 'champion' 'of' 'princeton' '.' 'do' 'not' 'think'\n",
      " 'that' 'i' 'am' 'very' 'much' 'impressed' 'by' 'that' 'as' 'a' 'boxing' 'title' ',' 'but' 'it' 'meant' 'a'\n",
      " 'lot' 'to' 'cohn' '.' 'he' 'cared' 'nothing' 'for' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "print(len(tok_val), tok_val[:40])\n",
    "print(len(tok_trn), tok_trn[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "(PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 25704),\n",
       " ('the', 20367),\n",
       " (',', 15275),\n",
       " ('and', 11130),\n",
       " ('i', 8580),\n",
       " ('to', 6627),\n",
       " (\"'\", 6117),\n",
       " ('he', 6019),\n",
       " ('a', 5978),\n",
       " ('it', 5445),\n",
       " ('you', 5435),\n",
       " ('of', 5043),\n",
       " ('was', 4866),\n",
       " ('in', 4500),\n",
       " ('said', 3947),\n",
       " ('that', 3401),\n",
       " ('?', 2928),\n",
       " ('had', 2364),\n",
       " ('on', 2325),\n",
       " ('his', 2247)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for p in tok_trn)\n",
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
