{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FitLam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip\n",
    "\n",
    "download dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR maybe use Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: wget: not found\r\n"
     ]
    }
   ],
   "source": [
    "# !wget -nH -r -np http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "\n",
    "from fastai.text import *\n",
    "from torchtext import vocab, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/fitlam')\n",
    "PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(Path('/notebooks/volume/full_hemingway.txt'), encoding='utf-8')\n",
    "fulltext = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the joined collection of hemingway books 80/20. This may not be very valid, maybe the whole book should be a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to files\n",
    "def save_txt_file(name, txt):    \n",
    "    f=open(PATH/name, mode='w', encoding='utf-8')\n",
    "    f.write(txt)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text of unneccesary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_txt = set(fulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cln_full_txt = fulltext.replace('\\u2009', ' ').replace('“', '').replace('”', '').replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' our Lord and Saviour.  No, said Doc Fischer. It’s a natural thing. It’s the way you are supposed to be and later on you will think you are very fortunate.  Oh, you don’t understand, the boy said.  Listen, Doc Fischer said and he told the boy certain things.  No. I won’t listen. You can’t make me li'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.random.randint(1,len(cln_full_txt))\n",
    "cln_full_txt[r:(r+300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng = len(cln_full_txt)\n",
    "trn_str = cln_full_txt[0:int(lng*0.8)]\n",
    "val_str = cln_full_txt[int(lng*0.8):-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = Tokenizer().proc_text(trn_str)\n",
    "tok_val = Tokenizer().proc_text(val_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91414 [' ' 'it' 'was' 'a' 'one' '-' 'road' 'show' '.' 'the' 'road' 'was' 'screened' 'because' 'it' 'was' 'in'\n",
      " 'sight' 'of' 'the' 'austrians' 'across' 'the' 'river' '.' 'here' 'at' 'the' 'brickyard' 'we' 'were'\n",
      " 'sheltered' 'from' 'rifle' 'or' 'machine' '-' 'gun' 'fire' 'by'] \n",
      "\n",
      "363798 [' ' 'robert' 'cohn' 'was' 'once' 'middleweight' 'boxing' 'champion' 'of' 'princeton' '.' 'do' 'not' 'think'\n",
      " 'that' 'i' 'am' 'very' 'much' 'impressed' 'by' 'that' 'as' 'a' 'boxing' 'title' ',' 'but' 'it' 'meant' 'a'\n",
      " 'lot' 'to' 'cohn' '.' 'he' 'cared' 'nothing' 'for' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "print(len(tok_val), tok_val[:40], '\\n')\n",
    "print(len(tok_trn), tok_trn[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 25704),\n",
       " ('the', 20367),\n",
       " (',', 15275),\n",
       " ('and', 11130),\n",
       " ('i', 8580),\n",
       " ('to', 6627),\n",
       " (\"'\", 6117),\n",
       " ('he', 6019),\n",
       " ('a', 5978),\n",
       " ('it', 5445)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for p in tok_trn)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE TRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = Path('data/wikitext/models/wt103')\n",
    "LM_PATH = Path(PRE_PATH/'fwd_wt103.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts.items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
